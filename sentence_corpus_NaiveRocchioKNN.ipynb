{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    " #Applying Naive Bayes, Rocchio, KNN classiffier on Sentence Corpus datasets\n",
    "\n",
    "\n",
    "#import libraries\n",
    "import os\n",
    "import json\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from textblob.classifiers import DecisionTreeClassifier\n",
    "from textblob.classifiers import NLTKClassifier\n",
    "import time\n",
    "import nltk.classify\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "class SVMClassifier(NLTKClassifier):\n",
    "    #\"\"\"Class that wraps around nltk.classify module for Naive bayes Classifier\"\"\"\n",
    "\n",
    "    nltk_class = nltk.classify.SklearnClassifier(LinearSVC())\n",
    "#class that wrap around ntlk.classify module for Rochio classifier\n",
    "class RocchioClassifier(NLTKClassifier):\n",
    "    \"\"\"Class that wraps around nltk.classify module for SVM Classifier\"\"\"\n",
    "\n",
    "    nltk_class = nltk.classify.SklearnClassifier(NearestCentroid())\n",
    "\n",
    "#class that wrap around ntlk.classify module for KNN classfier\n",
    "class NNClassifier(NLTKClassifier):\n",
    "    \"\"\"Class that wraps around nltk.classify module for SVM Classifier\"\"\"\n",
    "\n",
    "    nltk_class = nltk.classify.SklearnClassifier(KNeighborsClassifier())\n",
    "\n",
    "\n",
    "#Lists all file paths from given directory  \n",
    "def list_files_from_directory(directory):  \n",
    "    ret_val = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".txt\"):\n",
    "            ret_val.append(str(directory) + \"/\" + str(file))\n",
    "    return ret_val\n",
    "\n",
    "#Reads all lines from file on given path\n",
    "#omitting hash from the code\n",
    "def read_file(path):\n",
    "    f = open(path, \"r\")\n",
    "    read = f.readlines()\n",
    "    ret_val = []\n",
    "    for line in read:\n",
    "        if line.startswith(\"#\"):\n",
    "            pass\n",
    "        else:\n",
    "            ret_val.append(line)\n",
    "    return ret_val\n",
    "\n",
    "#Returns sentence category and sentence in given line\n",
    "def process_line(line):\n",
    "\n",
    "#splitting line on tab\n",
    "    if \"\\t\" in line:\n",
    "        splits = line.split(\"\\t\")  \n",
    "        s_category = splits[0]      \n",
    "        sentence = splits[1].lower()\n",
    "#removing stop words\n",
    "        for sw in stopwords:\n",
    "            sentence = sentence.replace(sw, \"\")\n",
    "        pattern = re.compile(\"[^\\w']\")\n",
    "        sentence = pattern.sub(' ', sentence)\n",
    "        sentence = re.sub(' +', ' ', sentence)\n",
    "        return s_category, sentence\n",
    "    else:\n",
    "        splits = line.split(\" \") #if not split on basis of space\n",
    "        s_category = splits[0]\n",
    "        sentence = line[len(s_category)+1:].lower()\n",
    "        for sw in stopwords:\n",
    "            sentence = sentence.replace(sw, \"\")\n",
    "        pattern = re.compile(\"[^\\w']\")\n",
    "        sentence = pattern.sub(' ', sentence)\n",
    "        sentence = re.sub(' +', ' ', sentence) #removing space plus space\n",
    "        return s_category, sentence\n",
    "\n",
    "\n",
    "def create_json_file(input_folder, destination_file):\n",
    "    \"\"\"Writes training data from given folder into formatted JSON file\"\"\"\n",
    "\n",
    "    tr_folder = list_files_from_directory(input_folder)\n",
    "    all_json = []\n",
    "    for file in tr_folder:\n",
    "        lines = read_file(file)\n",
    "        for line in lines:\n",
    "            c, s = process_line(line)\n",
    "            if s.endswith('\\n'):\n",
    "                s = s[:-1]\n",
    "            json_data = {\n",
    "                'text': s,  #giving label to sentences\n",
    "                'label': c  #giving label to category\n",
    "            }\n",
    "            all_json.append(json_data)\n",
    "\n",
    "    with open(destination_file, \"w\") as outfile:\n",
    "        json.dump(all_json, outfile)\n",
    "\n",
    "\n",
    "def prepare_test_data(input_folder):\n",
    "    \"\"\"Maps each sentence to it's category\"\"\"\n",
    "\n",
    "    test_folder = list_files_from_directory(input_folder)\n",
    "    t_sentences = []\n",
    "    t_categories = []\n",
    "    for file in test_folder:\n",
    "        lines = read_file(file)\n",
    "        for line in lines:\n",
    "            c, s = process_line(line)\n",
    "            if s.endswith('\\n'):\n",
    "                s = s[:-1]\n",
    "            t_sentences.append(s)\n",
    "            t_categories.append(c)\n",
    "    return t_categories, t_sentences\n",
    "\n",
    "# main\n",
    "\n",
    "# loading stopwords\n",
    "\n",
    "input_stopwords = read_file(\"C:/Users/HP/Desktop/word_lists/stopwords.txt\")\n",
    "stopwords = []\n",
    "for word in input_stopwords:\n",
    "    if word.endswith('\\n'):\n",
    "        word = word[:-1]\n",
    "        stopwords.append(word)\n",
    "\n",
    "\n",
    "# prepare training and test data\n",
    "create_json_file(\"training_set\", \"training.json\")\n",
    "categories, sentences = prepare_test_data(\"test_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Naive Bayes Classifier...\n",
      "Training Naive Bayes Classifier completed...\n",
      "Training time (in seconds): 4.319633722305298\n",
      "Testing Naive Bayes Classifier...\n",
      "Number of tests: 1113\n",
      "Correct tests: 726\n",
      "Naive Bayes Classifier accuracy: 0.6522911051212938\n",
      "Testing time (in seconds): 68.85488390922546\n"
     ]
    }
   ],
   "source": [
    "# Bayes Classifier\n",
    "print(\"Training Naive Bayes Classifier...\")\n",
    "start_nbc = time.time()\n",
    "with open('training.json', 'r') as training:\n",
    "    nbc = NaiveBayesClassifier(training, format=\"json\")\n",
    "stop_nbc = time.time()\n",
    "print(\"Training Naive Bayes Classifier completed...\")\n",
    "elapsed = stop_nbc - start_nbc\n",
    "print(\"Training time (in seconds): \" + str(elapsed))\n",
    "print(\"Testing Naive Bayes Classifier...\")\n",
    "correct = 0\n",
    "start_nbc = time.time()\n",
    "for i in range(0, len(sentences)):\n",
    "    category = str(nbc.classify(sentences[i])).lower()\n",
    "    expected = str(categories[i]).lower()\n",
    "    if category == expected:\n",
    "        correct += 1\n",
    "stop_nbc = time.time()\n",
    "elapsed = stop_nbc - start_nbc\n",
    "print(\"Number of tests: \" + str(len(sentences)))\n",
    "print(\"Correct tests: \" + str(correct))\n",
    "accuracy = correct / len(sentences)\n",
    "print(\"Naive Bayes Classifier accuracy: \" + str(accuracy))\n",
    "print(\"Testing time (in seconds): \" + str(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Rocchio Classifier...\n",
      "Training Rocchio Classifier completed...\n",
      "Training time (in seconds): 4.3021416664123535\n",
      "Testing Rocchio Classifier...\n",
      "Number of tests: 1113\n",
      "Correct tests: 719\n",
      "Rocchio Classifier accuracy: 0.6460017969451932\n",
      "Testing time (in seconds): 8.786561965942383\n"
     ]
    }
   ],
   "source": [
    "# Rocchio\n",
    "print(\"Training Rocchio Classifier...\")\n",
    "start_nbc = time.time()\n",
    "with open('training.json', 'r') as training:\n",
    "    nbc = RocchioClassifier(training, format=\"json\")\n",
    "stop_nbc = time.time()\n",
    "print(\"Training Rocchio Classifier completed...\")\n",
    "elapsed = stop_nbc - start_nbc\n",
    "print(\"Training time (in seconds): \" + str(elapsed))\n",
    "print(\"Testing Rocchio Classifier...\")\n",
    "correct = 0\n",
    "start_nbc = time.time()\n",
    "for i in range(0, len(sentences)):\n",
    "    category = str(nbc.classify(sentences[i])).lower()\n",
    "    expected = str(categories[i]).lower()\n",
    "    if category == expected:\n",
    "        correct += 1\n",
    "stop_nbc = time.time()\n",
    "elapsed = stop_nbc - start_nbc\n",
    "print(\"Number of tests: \" + str(len(sentences)))\n",
    "print(\"Correct tests: \" + str(correct))\n",
    "accuracy = correct / len(sentences)\n",
    "print(\"Rocchio Classifier accuracy: \" + str(accuracy))\n",
    "print(\"Testing time (in seconds): \" + str(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Knearest Classifier...\n",
      "Training Knearest Classifier completed...\n",
      "Training time (in seconds): 4.2402448654174805\n",
      "Testing Knearest Classifier...\n",
      "Number of tests: 1113\n",
      "Correct tests: 625\n",
      "Knearest Classifier accuracy: 0.5615453728661276\n",
      "Testing time (in seconds): 9.378696203231812\n"
     ]
    }
   ],
   "source": [
    "# Knearest\n",
    "\n",
    "print(\"Training Knearest Classifier...\")\n",
    "start_nbc = time.time()\n",
    "with open('training.json', 'r') as training:\n",
    "    nbc = NNClassifier(training, format=\"json\")\n",
    "stop_nbc = time.time()\n",
    "print(\"Training Knearest Classifier completed...\")\n",
    "elapsed = stop_nbc - start_nbc\n",
    "print(\"Training time (in seconds): \" + str(elapsed))\n",
    "print(\"Testing Knearest Classifier...\")\n",
    "correct = 0\n",
    "start_nbc = time.time()\n",
    "for i in range(0, len(sentences)):\n",
    "    category = str(nbc.classify(sentences[i])).lower()\n",
    "    expected = str(categories[i]).lower()\n",
    "    if category == expected:\n",
    "        correct += 1\n",
    "stop_nbc = time.time()\n",
    "elapsed = stop_nbc - start_nbc\n",
    "print(\"Number of tests: \" + str(len(sentences)))\n",
    "print(\"Correct tests: \" + str(correct))\n",
    "accuracy = correct / len(sentences)\n",
    "print(\"Knearest Classifier accuracy: \" + str(accuracy))\n",
    "print(\"Testing time (in seconds): \" + str(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
